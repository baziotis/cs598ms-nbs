{
  "cells": [
    {
      "raw": "import pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n# import plotly.graph_objects as go\n# from fbprophet import Prophet\nimport pycountry\n# import plotly.express as px\nfrom collections import namedtuple",
      "total-ns": 2717916328
    },
    {
      "raw": "df = pd.read_csv('../input/covid_19_data.csv',parse_dates=['Last Update'])\ndf.rename(columns={'ObservationDate':'Date', 'Country/Region':'Country'}, inplace=True)\n\ndf_confirmed = pd.read_csv(\"../input/time_series_covid_19_confirmed.csv\")\ndf_recovered = pd.read_csv(\"../input/time_series_covid_19_recovered.csv\")\ndf_deaths = pd.read_csv(\"../input/time_series_covid_19_deaths.csv\")\n\ndf_confirmed.rename(columns={'Country/Region':'Country'}, inplace=True)\ndf_recovered.rename(columns={'Country/Region':'Country'}, inplace=True)\ndf_deaths.rename(columns={'Country/Region':'Country'}, inplace=True)",
      "total-ns": 81863591
    },
    {
      "raw": "df_confirmed.head()",
      "total-ns": 428378
    },
    {
      "raw": "df.head()",
      "total-ns": 793497
    },
    {
      "raw": "df.tail()",
      "total-ns": 265303
    },
    {
      "raw": "df2 = df.groupby([\"Date\", \"Country\", \"Province/State\"])[['SNo', 'Date', 'Province/State', 'Country', 'Confirmed', 'Deaths', 'Recovered']].sum().reset_index()",
      "total-ns": 17987750
    },
    {
      "raw": "df2",
      "total-ns": 344818
    },
    {
      "raw": "df.query('Country==\"Mainland China\"').groupby(\"Last Update\")[['Confirmed', 'Deaths', 'Recovered']].sum().reset_index()",
      "total-ns": 7960632
    },
    {
      "raw": "df.groupby(\"Country\")[['Confirmed', 'Deaths', 'Recovered']].sum().reset_index()",
      "total-ns": 4561435
    },
    {
      "raw": "df.groupby('Date').sum()",
      "total-ns": 3684209
    },
    {
      "raw": "confirmed = df.groupby('Date').sum()['Confirmed'].reset_index()\ndeaths = df.groupby('Date').sum()['Deaths'].reset_index()\nrecovered = df.groupby('Date').sum()['Recovered'].reset_index()",
      "total-ns": 12900075
    },
    {
      "raw": "# fig = go.Figure()\n# fig.add_trace(go.Bar(x=confirmed['Date'],\n#                 y=confirmed['Confirmed'],\n#                 name='Confirmed',\n#                 marker_color='blue'\n#                 ))\n# fig.add_trace(go.Bar(x=deaths['Date'],\n#                 y=deaths['Deaths'],\n#                 name='Deaths',\n#                 marker_color='Red'\n#                 ))\n# fig.add_trace(go.Bar(x=recovered['Date'],\n#                 y=recovered['Recovered'],\n#                 name='Recovered',\n#                 marker_color='Green'\n#                 ))\n\n# fig.update_layout(\n#     title='Worldwide Corona Virus Cases - Confirmed, Deaths, Recovered (Bar Chart)',\n#     xaxis_tickfont_size=14,\n#     yaxis=dict(\n#         title='Number of Cases',\n#         titlefont_size=16,\n#         tickfont_size=14,\n#     ),\n#     legend=dict(\n#         x=0,\n#         y=1.0,\n#         bgcolor='rgba(255, 255, 255, 0)',\n#         bordercolor='rgba(255, 255, 255, 0)'\n#     ),\n#     barmode='group',\n#     bargap=0.15, # gap between bars of adjacent location coordinates.\n#     bargroupgap=0.1 # gap between bars of the same location coordinate.\n# )\n# fig.show()",
      "total-ns": 322911
    },
    {
      "raw": "# fig = go.Figure()\n# fig.add_trace(go.Scatter(x=confirmed['Date'], \n#                          y=confirmed['Confirmed'],\n#                          mode='lines+markers',\n#                          name='Confirmed',\n#                          line=dict(color='blue', width=2)\n#                         ))\n# fig.add_trace(go.Scatter(x=deaths['Date'], \n#                          y=deaths['Deaths'],\n#                          mode='lines+markers',\n#                          name='Deaths',\n#                          line=dict(color='Red', width=2)\n#                         ))\n# fig.add_trace(go.Scatter(x=recovered['Date'], \n#                          y=recovered['Recovered'],\n#                          mode='lines+markers',\n#                          name='Recovered',\n#                          line=dict(color='Green', width=2)\n#                         ))\n# fig.update_layout(\n#     title='Worldwide Corona Virus Cases - Confirmed, Deaths, Recovered (Line Chart)',\n#     xaxis_tickfont_size=14,\n#     yaxis=dict(\n#         title='Number of Cases',\n#         titlefont_size=16,\n#         tickfont_size=14,\n#     ),\n#     legend=dict(\n#         x=0,\n#         y=1.0,\n#         bgcolor='rgba(255, 255, 255, 0)',\n#         bordercolor='rgba(255, 255, 255, 0)'\n#     )\n# )\n# fig.show()",
      "total-ns": 222459
    },
    {
      "raw": "df_confirmed = df_confirmed[[\"Province/State\",\"Lat\",\"Long\",\"Country\"]]\ndf_temp = df.copy()\ndf_temp['Country'].replace({'Mainland China': 'China'}, inplace=True)\ndf_latlong = pd.merge(df_temp, df_confirmed, on=[\"Country\", \"Province/State\"])",
      "total-ns": 15873496
    },
    {
      "raw": "# fig = px.density_mapbox(df_latlong, \n#                         lat=\"Lat\", \n#                         lon=\"Long\", \n#                         hover_name=\"Province/State\", \n#                         hover_data=[\"Confirmed\",\"Deaths\",\"Recovered\"], \n#                         animation_frame=\"Date\",\n#                         color_continuous_scale=\"Portland\",\n#                         radius=7, \n#                         zoom=0,height=700)\n# fig.update_layout(title='Worldwide Corona Virus Cases Time Lapse - Confirmed, Deaths, Recovered',\n#                   font=dict(family=\"Courier New, monospace\",\n#                             size=18,\n#                             color=\"#7f7f7f\")\n#                  )\n# fig.update_layout(mapbox_style=\"open-street-map\", mapbox_center_lon=0)\n# fig.update_layout(margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0})\n\n\n# fig.show()",
      "total-ns": 250197
    },
    {
      "raw": "confirmed = df2.groupby(['Date', 'Country']).sum()[['Confirmed']].reset_index()\ndeaths = df2.groupby(['Date', 'Country']).sum()[['Deaths']].reset_index()\nrecovered = df2.groupby(['Date', 'Country']).sum()[['Recovered']].reset_index()",
      "total-ns": 16849007
    },
    {
      "raw": "latest_date = confirmed['Date'].max()\nlatest_date",
      "total-ns": 579534
    },
    {
      "raw": "confirmed = confirmed[(confirmed['Date']==latest_date)][['Country', 'Confirmed']]\ndeaths = deaths[(deaths['Date']==latest_date)][['Country', 'Deaths']]\nrecovered = recovered[(recovered['Date']==latest_date)][['Country', 'Recovered']]",
      "total-ns": 3423778
    },
    {
      "raw": "all_countries = confirmed['Country'].unique()\nprint(\"Number of countries/regions with cases: \" + str(len(all_countries)))\nprint(\"Countries/Regions with cases: \")\nfor i in all_countries:\n    print(\"    \" + str(i))",
      "total-ns": 701889
    },
    {
      "raw": "print(list(country.name for country in pycountry.countries))",
      "total-ns": 3601804
    },
    {
      "raw": "print('UK' in list(country.name for country in pycountry.countries))\nprint('United Kingdom' in list(country.name for country in pycountry.countries))",
      "total-ns": 829232
    },
    {
      "raw": "confirmed2 = confirmed.copy()\ndeaths2 = deaths.copy()\nrecovered2 = recovered.copy()\nbubble_plot_dfs = [confirmed2, deaths2, recovered2]\nfor df_ in bubble_plot_dfs:\n    df_[\"Country\"].replace({'Mainland China': 'China'}, inplace=True)\n    df_[\"Country\"].replace({'UK': 'United Kingdom'}, inplace=True)\n    df_[\"Country\"].replace({'US': 'United States'}, inplace=True)",
      "total-ns": 3061555
    },
    {
      "raw": "countries = {}\nfor country in pycountry.countries:\n    countries[country.name] = country.alpha_3\n    \nconfirmed2[\"iso_alpha\"] = confirmed2[\"Country\"].map(countries.get)\ndeaths2[\"iso_alpha\"] = deaths2[\"Country\"].map(countries.get)\nrecovered2[\"iso_alpha\"] = recovered2[\"Country\"].map(countries.get)",
      "total-ns": 1983026
    },
    {
      "raw": "plot_data_confirmed = confirmed2[[\"iso_alpha\",\"Confirmed\", \"Country\"]]\nplot_data_deaths = deaths2[[\"iso_alpha\",\"Deaths\"]]\nplot_data_recovered = recovered2[[\"iso_alpha\",\"Recovered\"]]",
      "total-ns": 2062454
    },
    {
      "raw": "# fig = px.scatter_geo(plot_data_confirmed, locations=\"iso_alpha\", color=\"Country\",\n#                      hover_name=\"iso_alpha\", size=\"Confirmed\",\n#                      projection=\"natural earth\", title = 'Worldwide Confirmed Cases')\n# fig.show()",
      "total-ns": 145323
    },
    {
      "raw": "# fig = px.scatter_geo(plot_data_deaths, locations=\"iso_alpha\", color=\"Deaths\",\n#                      hover_name=\"iso_alpha\", size=\"Deaths\",\n#                      projection=\"natural earth\", title=\"Worldwide Death Cases\")\n# fig.show()",
      "total-ns": 163628
    },
    {
      "raw": "# fig = px.scatter_geo(plot_data_recovered, locations=\"iso_alpha\", color=\"Recovered\",\n#                      hover_name=\"iso_alpha\", size=\"Recovered\",\n#                      projection=\"natural earth\", title=\"Worldwide Recovered Cases\")\n# fig.show()",
      "total-ns": 163022
    },
    {
      "raw": "confirmed = df.groupby('Date').sum()['Confirmed'].reset_index()\ndeaths = df.groupby('Date').sum()['Deaths'].reset_index()\nrecovered = df.groupby('Date').sum()['Recovered'].reset_index()",
      "total-ns": 13204837
    },
    {
      "raw": "confirmed.columns = ['ds','y']\n#confirmed['ds'] = confirmed['ds'].dt.date\nconfirmed['ds'] = pd.to_datetime(confirmed['ds'])",
      "total-ns": 1087031
    },
    {
      "raw": "confirmed.head()",
      "total-ns": 337595
    },
    {
      "raw": "# m = Prophet(interval_width=0.95)\n# m.fit(confirmed)\n# future = m.make_future_dataframe(periods=7)\n# future_confirmed = future.copy() # for non-baseline predictions later on\n# future.tail()",
      "total-ns": 117354
    },
    {
      "raw": "# forecast = m.predict(future)\n# forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()",
      "total-ns": 80811
    },
    {
      "raw": "# confirmed_forecast_plot = m.plot(forecast)",
      "total-ns": 104258
    },
    {
      "raw": "# forecast_components = m.plot_components(forecast)",
      "total-ns": 90767
    },
    {
      "raw": "deaths.columns = ['ds','y']\ndeaths['ds'] = pd.to_datetime(deaths['ds'])",
      "total-ns": 979698
    },
    {
      "raw": "# m = Prophet(interval_width=0.95)\n# m.fit(deaths)\n# future = m.make_future_dataframe(periods=7)\n# future_deaths = future.copy() # for non-baseline predictions later on\n# future.tail()",
      "total-ns": 125788
    },
    {
      "raw": "# forecast = m.predict(future)\n# forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()",
      "total-ns": 86377
    },
    {
      "raw": "# deaths_forecast_plot = m.plot(forecast)",
      "total-ns": 107545
    },
    {
      "raw": "# forecast_components = m.plot_components(forecast)",
      "total-ns": 95241
    },
    {
      "raw": "recovered.columns = ['ds','y']\nrecovered['ds'] = pd.to_datetime(recovered['ds'])",
      "total-ns": 988876
    },
    {
      "raw": "# m = Prophet(interval_width=0.95)\n# m.fit(recovered)\n# future = m.make_future_dataframe(periods=7)\n# future_recovered = future.copy() # for non-baseline predictions later on\n# future.tail()",
      "total-ns": 113881
    },
    {
      "raw": "# forecast = m.predict(future)\n# forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail()",
      "total-ns": 79862
    },
    {
      "raw": "# recovered_forecast_plot = m.plot(forecast)",
      "total-ns": 97267
    },
    {
      "raw": "# forecast_components = m.plot_components(forecast)",
      "total-ns": 90332
    },
    {
      "raw": "days_to_forecast = 7 # changable\nfirst_forecasted_date = sorted(list(set(df2['Date'].values)))[-days_to_forecast]\n\nprint('The first date to perform forecasts for is: ' + str(first_forecasted_date))",
      "total-ns": 734478
    },
    {
      "raw": "confirmed_df = df2[['SNo', 'Date','Province/State', 'Country', 'Confirmed']]\nconfirmed_df",
      "total-ns": 2041800
    },
    {
      "raw": "deaths_df = df2[['SNo', 'Date','Province/State', 'Country', 'Deaths']]\ndeaths_df",
      "total-ns": 1604410
    },
    {
      "raw": "recovered_df = df2[['SNo', 'Date','Province/State', 'Country', 'Recovered']]\nrecovered_df",
      "total-ns": 1503343
    },
    {
      "raw": "def make_forecasts(all_countries, confirmed_df, deaths_df, recovered_df, days_to_forecast, first_forecasted_date, mode):\n    forecast_dfs = []\n    absolute_errors = [] # collate absolute errors so that we can find MAE later on\n    counter = 0 # arbitrary counter to output snippet of result_val_df only once, when it is 1\n    for country in all_countries:\n        try:\n            assert(country in confirmed_df['Country'].values)\n            print('Country ' + str(country) + ' is listed! ')\n            country_confirmed_df = confirmed_df[(confirmed_df['Country'] == country)]\n            country_deaths_df = deaths_df[(deaths_df['Country'] == country)]\n            country_recovered_df = recovered_df[(recovered_df['Country'] == country)]\n            country_dfs = [('Confirmed', country_confirmed_df), \n                           ('Deaths', country_deaths_df), \n                           ('Recovered', country_recovered_df)]\n            states_in_country = country_confirmed_df['Province/State'].unique()\n            for state in states_in_country:\n                try:\n                    state_dfs = [] # to store forecasts for Confirmed, Deaths and Recovered\n\n                    assert(state in country_confirmed_df['Province/State'].values)\n\n                    # make forecasts for each case type (Confirmed, Deaths, Recovered)\n                    for country_df_tup in country_dfs:\n                        case_type = country_df_tup[0]\n                        country_df = country_df_tup[1]\n                        state_df = country_df[(country_df['Province/State'] == state)]\n\n                        # data preparation for forecast with Prophet at state level\n                        state_df = state_df[['Date', case_type]]\n                        state_df.columns = ['ds','y']\n                        state_df['ds'] = pd.to_datetime(state_df['ds'])\n\n                        state_df_val = state_df[(state_df['ds'] >= pd.to_datetime(first_forecasted_date))] # validation set\n                        state_df = state_df[(state_df['ds'] < pd.to_datetime(first_forecasted_date))] # train set\n\n                        # if mode == 'default':\n                        #     m = Prophet()\n                        # elif mode == 'custom':\n                        #     m = Prophet(daily_seasonality=False, weekly_seasonality=False, yearly_seasonality=False)\n                        #     m.add_seasonality(name='monthly', period=30.5, fourier_order=10)\n                        #     m.add_seasonality(name='weekly', period=7, fourier_order=21)\n                        #     m.add_seasonality(name='daily', period=1, fourier_order=3)\n                        # m.fit(state_df)\n                        # future = m.make_future_dataframe(periods=days_to_forecast)\n                        # forecast = m.predict(future)\n\n                        # # evaluate forecasts with validation set and save absolute errors to absolute_errors\n                        # forecast_df = forecast[['ds', 'yhat']]\n                        # result_df = forecast_df[(forecast_df['ds'] >= pd.to_datetime(first_forecasted_date))]\n                        # result_val_df = result_df.merge(state_df_val, on=['ds'])\n                        # result_val_df['abs_diff'] = (result_val_df['y'] - result_val_df['yhat']).abs()\n                        # absolute_errors += list(result_val_df['abs_diff'].values)\n\n                        # # the following allows the user to check the output at particular checkpoints. Feel free to change!\n                        # if counter == 1:\n                        #     print('Printing snippet of result_val_df: \\n')\n                        #     print(result_val_df)\n                        #     print(absolute_errors)\n                        # counter += 1\n\n                        # # save results to dataframe\n                        # forecast_df['Province/State'] = state\n                        # forecast_df['Country/Region'] = country\n                        # forecast_df.rename(columns={'yhat':case_type}, inplace=True)\n                        # state_dfs += [forecast_df.tail(days_to_forecast)]\n\n                    merged_df = state_dfs[0].merge(state_dfs[1],on=['ds', 'Province/State', 'Country/Region']).merge(state_dfs[2],on=['ds', 'Province/State', 'Country/Region'])\n                    forecast_dfs += [merged_df]\n                except:\n                    continue\n        except:\n            print('Country ' + str(country) + ' is not listed! ')\n            continue\n    results_tup = namedtuple('results_tup', ['forecast_dfs', 'absolute_errors'])\n    return results_tup(forecast_dfs, absolute_errors)",
      "total-ns": 2639130
    },
    {
      "raw": "forecast_results = make_forecasts(all_countries, confirmed_df, deaths_df, recovered_df, days_to_forecast, first_forecasted_date, 'default')\nabsolute_errors = forecast_results.absolute_errors",
      "total-ns": 5341114000
    },
    {
      "raw": "# forecast_results.forecast_dfs[0].tail(days_to_forecast) # example of a forecast",
      "total-ns": 222767
    },
    {
      "raw": "# forecasts_final = pd.concat(forecast_results.forecast_dfs, axis=0)\n# forecasts_final.sort_values(by='ds')\n# forecasts_final = forecasts_final[['ds', 'Province/State', 'Country/Region', 'Confirmed', 'Deaths', 'Recovered']]\n# forecasts_final.rename(columns={'ds':'ObservationDate'}, inplace=True)\n# for case_type in ['Confirmed', 'Deaths', 'Recovered']:\n#     forecasts_final[case_type] = forecasts_final[case_type].round() # round forecasts to integer as humans cannot be floats\n#     forecasts_final[forecasts_final[case_type] < 0] = 0 # replace negative forecasts to zero\n\n# forecasts_final",
      "total-ns": 161430
    },
    {
      "raw": "# forecasts_final.to_csv(\"forecasts_default_prophet.csv\", index=False) # save forecasts to CSV",
      "total-ns": 119906
    },
    {
      "raw": "# forecast_results_custom = make_forecasts(all_countries, confirmed_df, deaths_df, recovered_df, days_to_forecast, first_forecasted_date, 'custom')\n# absolute_errors_custom = forecast_results_custom.absolute_errors\n# forecast_dfs_custom = forecast_results_custom.forecast_dfs",
      "total-ns": 106982
    },
    {
      "raw": "# forecasts_final_custom = pd.concat(forecast_dfs_custom, axis=0)\n# forecasts_final_custom.sort_values(by='ds')\n# forecasts_final_custom = forecasts_final_custom[['ds', 'Province/State', 'Country/Region', 'Confirmed', 'Deaths', 'Recovered']]\n# forecasts_final_custom.rename(columns={'ds':'ObservationDate'}, inplace=True)\n# for case_type in ['Confirmed', 'Deaths', 'Recovered']:\n#     forecasts_final_custom[case_type] = forecasts_final_custom[case_type].round() # round forecasts to integer as humans cannot be floats\n#     forecasts_final_custom[forecasts_final_custom[case_type] < 0] = 0 # replace negative forecasts to zero\n\n# forecasts_final_custom",
      "total-ns": 273250
    },
    {
      "raw": "# forecasts_final_custom.to_csv(\"forecasts_custom_prophet.csv\", index=False) # save forecasts to CSV",
      "total-ns": 195280
    },
    {
      "raw": "# N = len(absolute_errors)\n# mean_absolute_error = sum(absolute_errors)/N\n# print('The mean absolute error for ' + str(days_to_forecast) + ' days of forecasts with the default Prophet model is: ' + str(round(mean_absolute_error, 2))) # round to 2 decimal places",
      "total-ns": 153234
    },
    {
      "raw": "# mean_absolute_error_custom = sum(absolute_errors_custom)/N\n# print('The mean absolute error for ' + str(days_to_forecast) + ' days of forecasts with the custom Prophet model is: ' + str(round(mean_absolute_error_custom, 2))) # round to 2 decimal places",
      "total-ns": 130599
    }
  ]
}