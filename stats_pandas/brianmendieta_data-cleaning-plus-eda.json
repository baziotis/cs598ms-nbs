{
  "cells": [
    {
      "raw": "# Import the necessary libraries\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\n#import zipfile\n#import kaggle",
      "total-ns": 3156792821
    },
    {
      "raw": "# Uncomment the import to extract the file from Kaggle with your key\n#!kaggle datasets download -d rashikrahmanpritom/data-science-job-posting-on-glassdoor",
      "total-ns": 168443
    },
    {
      "raw": "# Extract the files from the ZIP file\n#zip_name = 'data-science-job-posting-on-glassdoor.zip'\n#with zipfile.ZipFile(zip_name,'r') as file:\n#    file.extractall()",
      "total-ns": 96214
    },
    {
      "raw": "# Read the .csv file as a pandas dataframe\njob_data = pd.read_csv(\"../input/Uncleaned_DS_jobs.csv\")",
      "total-ns": 45474687
    },
    {
      "raw": "# Explore the data\njob_data.info()",
      "total-ns": 20533995
    },
    {
      "raw": "job_data.shape",
      "total-ns": 307651
    },
    {
      "raw": "# Check the information structure\njob_data.head()",
      "total-ns": 250624
    },
    {
      "raw": "# Drop the index column\njob_data.drop('index',axis=1,inplace=True)",
      "total-ns": 1418889
    },
    {
      "raw": "# Check for duplicates\njob_data[job_data.duplicated()].shape\njob_data[job_data.duplicated()]",
      "total-ns": 19794320
    },
    {
      "raw": "# Drop duplicates\njob_data.drop_duplicates(inplace=True)",
      "total-ns": 7319850
    },
    {
      "raw": "# Check the shape again\njob_data.shape",
      "total-ns": 244209
    },
    {
      "raw": "# Set appropiate column names in the form of lowercase words separated by '_'\njob_data.rename(columns= lambda header: header.lower().replace(\" \",\"_\"), inplace= True)",
      "total-ns": 639193
    },
    {
      "raw": "# Inspect the Job title column\njob_data[\"job_title\"][:150]",
      "total-ns": 366699
    },
    {
      "raw": "# Make the replacement\njob_data[\"job_title\"]=job_data.loc[:,\"job_title\"].str.replace(\"(Sr.)\",\"sr.\")",
      "total-ns": 1201649
    },
    {
      "raw": "# Delete the rest of the instances using a regex\njob_data[\"job_title\"]=job_data.loc[:,\"job_title\"].str.extract('([^()]+)')",
      "total-ns": 1647051
    },
    {
      "raw": "#Replace the special characters with an empty value by defining a regex pattern\njob_data['job_title'] = job_data['job_title'].str.replace(r'[^a-zA-Z0-9-,/\\s]','',regex=True)",
      "total-ns": 1608091
    },
    {
      "raw": "#Inspect the salary estimate column\njob_data['salary_estimate'][100:200]",
      "total-ns": 344513
    },
    {
      "raw": "# Define a function to extract the salary limits\ndef extract_values(text):\n    extracted_integer = ''\n    modified_string = ''\n    \n    for i in range(len(text)):\n        if i+1 < len(text):\n            if text[i].isdigit():\n                extracted_integer += text[i]\n                if not text[i+1].isdigit():\n                    break\n        if i == len(text) - 1 and text[i].isdigit():\n            extracted_integer += text[i]\n    \n    if extracted_integer:\n        modified_string = text[:text.find(extracted_integer)] + text[text.find(extracted_integer) + len(extracted_integer):]\n        extracted_integer = int(extracted_integer)\n    \n    return extracted_integer, modified_string",
      "total-ns": 971261
    },
    {
      "raw": "#Obtain the minimum salary in the range\njob_data['min_salary_K$'], job_data['salary_estimate'] = zip(*job_data['salary_estimate'].apply(extract_values))",
      "total-ns": 3414936
    },
    {
      "raw": "#Obtain the maximum salary in the range\njob_data['max_salary_K$'], job_data['salary_estimate'] = zip(*job_data['salary_estimate'].apply(extract_values))",
      "total-ns": 3062445
    },
    {
      "raw": "#Drop the old salary range column\njob_data.drop('salary_estimate', axis=1, inplace=True)",
      "total-ns": 1434517
    },
    {
      "raw": "#Let's obtain the average of these ranges\njob_data['avg_salary_estimate'] = (np.round((job_data['min_salary_K$'] + job_data['max_salary_K$'])/2,decimals=0)).astype(int)\njob_data.head()",
      "total-ns": 1186759
    },
    {
      "raw": "#Inspect the job description column\njob_data['job_description'][:150]",
      "total-ns": 292013
    },
    {
      "raw": "job_data.loc[:,\"job_description\"]\njob_data.loc[job_data.loc[:,\"job_description\"]==\"-1\"]",
      "total-ns": 1863621
    },
    {
      "raw": "#Inspect the rating column\njob_data['rating'][:150]",
      "total-ns": 396040
    },
    {
      "raw": "job_data['rating'].unique()",
      "total-ns": 311534
    },
    {
      "raw": "# Replace rating mising values with NaN across the entire column\njob_data['rating'].replace(-1.0,np.nan,inplace=True)",
      "total-ns": 519460
    },
    {
      "raw": "job_data['rating'].unique()",
      "total-ns": 277492
    },
    {
      "raw": "# Inspect the company name column\njob_data['company_name'][:10]",
      "total-ns": 269481
    },
    {
      "raw": "job_data['company_name'] = job_data.loc[:,'company_name'].str.replace(r\"\\n\\d+(\\.\\d+)?\",'',regex=True)\njob_data.loc[:,\"company_name\"][:10]",
      "total-ns": 1536993
    },
    {
      "raw": "# Inspect the location column\njob_data['location'][:10]",
      "total-ns": 297221
    },
    {
      "raw": "# Check the counts of each unique location state\njob_data.loc[:,\"location\"].apply(lambda x: x.split(\",\")[-1]).value_counts()",
      "total-ns": 1020902
    },
    {
      "raw": "# Create the state column\njob_data['location_state'] = job_data['location'].apply(lambda x: x.split(',')[-1].strip())",
      "total-ns": 828800
    },
    {
      "raw": "# Replace the inconsistencies with their correct state abbreviation\ndef clean_location(jobs):\n    return (\n        jobs.loc[:, \"location_state\"]\n        .replace(\"California\",\"CA\")\n        .replace(\"Texas\",\"TX\")\n        .replace(\"Utah\",\"UT\")\n        .replace(\"New Jersey\",\"NJ\")\n        .replace(\"Remote\",\"n/a\")\n        .replace(\"United States\",\"n/a\")\n    )\n\njob_data = job_data.assign(\n    location_state = clean_location\n)",
      "total-ns": 1960278
    },
    {
      "raw": "job_data[\"location_state\"].value_counts()",
      "total-ns": 1085027
    },
    {
      "raw": "# Check if the location of the job and the HQ are in the place\njob_data['same_state'] = (job_data['location'] == job_data['headquarters']).astype(int)",
      "total-ns": 1317391
    },
    {
      "raw": "job_data.head()",
      "total-ns": 455159
    },
    {
      "raw": "# Inspect the headquarters column\njob_data['headquarters'].value_counts()",
      "total-ns": 607682
    },
    {
      "raw": "job_data['headquarters'] = job_data['headquarters'].apply(lambda x: x.replace('-1','n/a'))\njob_data[\"headquarters\"].value_counts()",
      "total-ns": 1390741
    },
    {
      "raw": "# Inspect the size column\nprint(job_data['size'][:100])\njob_data['size'].unique()",
      "total-ns": 1168433
    },
    {
      "raw": "# Handle the missing values correctly\ndef size_cleaning(jobs):\n    return (\n        jobs.loc[:, \"size\"]\n        .replace(\"-1\",\"n/a\")\n        .replace(\"Unknown\",\"n/a\")\n    )\n\njob_data = job_data.assign(\n    size = size_cleaning\n)",
      "total-ns": 1387046
    },
    {
      "raw": "job_data['size'].unique()",
      "total-ns": 475264
    },
    {
      "raw": "# Inspect the founded column\njob_data['founded'][:100]",
      "total-ns": 264193
    },
    {
      "raw": "#Clean the missing values\njob_data['founded'].replace(-1,np.nan,inplace=True)\njob_data['founded'].unique()",
      "total-ns": 701373
    },
    {
      "raw": "# obtain the years the company has been in the market and drop the founed column\ncurrent_year = datetime.now().year\njob_data['years_in_market'] = current_year - job_data['founded']\njob_data.drop('founded',axis=1,inplace=True)\njob_data.head()",
      "total-ns": 1455475
    },
    {
      "raw": "# Inspect the Type of ownership column\njob_data['type_of_ownership'][:100]",
      "total-ns": 330692
    },
    {
      "raw": "job_data['type_of_ownership'].unique()",
      "total-ns": 313239
    },
    {
      "raw": "def ownership(jobs):\n    return (\n        jobs.loc[:, \"type_of_ownership\"]\n        .replace(\"Nonprofit Organization\",\"Nonprofit\")\n        .replace(\"-1\",\"n/a\")\n        .replace(\"Unknown\",\"n/a\")\n        .replace(\"Company - Public\",\"Public\")\n        .replace(\"Company - Private\",\"Private\")\n        .replace(\"Other Organization\",\"Other\")   \n    )\n\njob_data = job_data.assign(\n    type_of_ownership = ownership\n)",
      "total-ns": 1783323
    },
    {
      "raw": "job_data['type_of_ownership'].unique()",
      "total-ns": 357611
    },
    {
      "raw": "# Inspect the industry column\njob_data['industry'].value_counts()",
      "total-ns": 587289
    },
    {
      "raw": "job_data[\"industry\"] = job_data[\"industry\"].apply(lambda x: x.replace(\"-1\",\"n/a\"))\njob_data['industry'].unique()",
      "total-ns": 1010870
    },
    {
      "raw": "# Inspect the sector column\njob_data['sector'].value_counts()",
      "total-ns": 814061
    },
    {
      "raw": "job_data['sector'] = job_data['sector'].apply(lambda x: x.replace(\"-1\",\"n/a\"))\njob_data['sector'].unique()",
      "total-ns": 1077589
    },
    {
      "raw": "# Inspect the revenue column\njob_data['revenue'].value_counts()",
      "total-ns": 872192
    },
    {
      "raw": "def revenue_cleanup(jobs):\n    return (\n        jobs.loc[:, \"revenue\"]\n        .replace(\"-1\",\"n/a\")\n        .replace(\"Unknown / Non-Applicable\",\"n/a\")\n    )\n\njob_data = job_data.assign(\n    revenue = revenue_cleanup\n)",
      "total-ns": 1701004
    },
    {
      "raw": "job_data['revenue']=job_data.loc[:,'revenue'].str.extract('([^()]+)')\njob_data['revenue'].value_counts()",
      "total-ns": 2156248
    },
    {
      "raw": "# Finally inspect the competitors column\njob_data['competitors'].value_counts()\n",
      "total-ns": 562387
    },
    {
      "raw": "np.round((488/659)*100,decimals=2)",
      "total-ns": 299507
    },
    {
      "raw": "#The percentage is too high so we drop this column\njob_data.drop('competitors',axis=1,inplace=True)",
      "total-ns": 733240
    },
    {
      "raw": "job_data.head()",
      "total-ns": 226817
    },
    {
      "raw": "# Check if we have any '-1' as missing values\njob_data[job_data.eq('-1').any(axis = 1)]",
      "total-ns": 1148482
    },
    {
      "raw": "# Check if we have a numerical missing value in any column \njob_data[job_data.eq(-1).any(axis = 1)]",
      "total-ns": 947984
    },
    {
      "raw": "# Define a simplification function\n\ndef role_defining(title): \n    if any(keyword in title.lower() for keyword in ['data scientist', 'data science']):\n        return 'Data Scientist'\n    elif any(keyword in title.lower() for keyword in ['data analyst', 'analyst']):\n        return 'Data Analyst'\n    elif 'data engineer' in title.lower():\n        return 'Data Engineer'\n    elif any(keyword in title.lower() for keyword in ['machine learning', 'ai']):\n        return 'Machine Learning Engineer'\n    else:\n        return 'Other'",
      "total-ns": 819560
    },
    {
      "raw": "# Apply the function to the new column\njob_data['job_role']= job_data['job_title'].apply(role_defining)\njob_data['job_role'].value_counts()",
      "total-ns": 1773691
    },
    {
      "raw": "def seniority_defining(title,description):\n    if any(keyword in title.lower() for keyword in ['jr.','jr','junior']) or any(keyword in description.lower() for keyword in ['jr.','jr','junior']):\n        return 'Jr'\n    elif any(keyword in title.lower() for keyword in ['sr.','sr','vp','senior']) or any(keyword in description.lower() for keyword in ['sr.','sr','vp','senior']):\n        return 'Sr'\n    else:\n        return 'Mid-Level'\n    \n\njob_data['job_seniority'] = job_data.apply(lambda row: seniority_defining(row['job_title'], row['job_description']), axis=1)\njob_data['job_seniority'].value_counts()",
      "total-ns": 57221206
    },
    {
      "raw": "job_data.head()",
      "total-ns": 331936
    },
    {
      "raw": "# Create dummy columns for each of the skill considered.\njob_data['excel'] = job_data.apply(lambda x: 1 if 'excel' in x.job_description.lower() else 0, axis=1)\njob_data['sql'] = job_data.apply(lambda x: 1 if 'sql' in x.job_description.lower() else 0, axis=1)\njob_data['python'] = job_data.apply(lambda x: 1 if 'python' in x.job_description.lower() else 0, axis=1)\njob_data['power_bi'] = job_data.apply(lambda x: 1 if 'power bi' in x.job_description.lower() else 0, axis=1)\njob_data['tableau'] = job_data.apply(lambda x: 1 if 'tableau' in x.job_description.lower() else 0, axis=1)\njob_data['scikit'] = job_data.apply(lambda x: 1 if 'scikit' in x.job_description.lower() else 0, axis=1)\njob_data['spark'] = job_data.apply(lambda x: 1 if 'spark' in x.job_description.lower() else 0, axis=1)",
      "total-ns": 93145918
    },
    {
      "raw": "print(job_data['excel'].value_counts())\nprint(job_data['sql'].value_counts())\nprint(job_data['python'].value_counts())\nprint(job_data['power_bi'].value_counts())\nprint(job_data['tableau'].value_counts())\nprint(job_data['scikit'].value_counts())\nprint(job_data['spark'].value_counts())",
      "total-ns": 5827388
    },
    {
      "raw": "job_data.head()",
      "total-ns": 448700
    },
    {
      "raw": "# job_data.to_csv('Cleaned_Job_Data.csv',index= False)\n# job_data.to_excel('Cleaned_Job_Data.xlsx',index=False)",
      "total-ns": 102316
    },
    {
      "raw": "# Include the necessary packages fro analysisi and visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline",
      "total-ns": 4105017526
    },
    {
      "raw": "# Obtain the basic statistics of the data frame\njob_data.describe()",
      "total-ns": 22699381
    },
    {
      "raw": "#Obtain the relationships between columns\n# sns.pairplot(job_data)",
      "total-ns": 176364
    },
    {
      "raw": "industry_salary = [\n    round(job_data.loc[job_data[\"industry\"]==\"Biotech & Pharmaceuticals\",\"avg_salary_estimate\"].mean(), 2),\n    round(job_data.loc[job_data[\"industry\"]==\"IT Services\",\"avg_salary_estimate\"].mean(), 2),\n    round(job_data.loc[job_data[\"industry\"]==\"Computer Hardware & Software\",\"avg_salary_estimate\"].mean(), 2),\n    round(job_data.loc[job_data[\"industry\"]==\"Aerospace & Defense\",\"avg_salary_estimate\"].mean(), 2),\n    round(job_data.loc[job_data[\"industry\"]==\"Enterprise Software & Network Solutions\",\"avg_salary_estimate\"].mean(), 2)\n]\n\ntop_paying_industries = [\n    \"Biotech & Pharmaceuticals\",\n    \"IT Services\",\n    \"Computer Hardware & Software\",\n    \"Aerospace & Defense\",\n    \"Enterprise Software & Network Solutions\"\n]\n\n# plt.bar(top_paying_industries, industry_salary)\n# plt.ylim(110, 140)\n# plt.xlabel(\"Job Industry\")\n# plt.ylabel(\"Average Salary\")\n\n# # Rotate the x-axis labels by 70 degrees\n# plt.xticks(rotation=70)\n\n# plt.show()",
      "total-ns": 2979845
    },
    {
      "raw": "# Let's start by analyzing the average salary for job postings\n# sns.boxplot(x=job_data['avg_salary_estimate'])",
      "total-ns": 153292
    },
    {
      "raw": "# We can define a new data frame to fit in better inside the avg. salary range\ndf = job_data[(job_data.avg_salary_estimate > 50) & (job_data.avg_salary_estimate < 200)] ",
      "total-ns": 2206818
    },
    {
      "raw": "df.shape",
      "total-ns": 318764
    },
    {
      "raw": "# Make a comparison between the years the company has been in the market and the avg. salary.\n# sns.lmplot(x='years_in_market',y='avg_salary_estimate',data=df)\n",
      "total-ns": 101387
    },
    {
      "raw": "# Generate a heatmap based on the numerical columns of the dataframe\n# fig, ax = plt.subplots(figsize=(10,10)) \nmatrix = np.triu(df.select_dtypes(include=[np.number]).corr())\n# sns.heatmap(df.select_dtypes(include=[np.number]).corr(),annot=True, fmt='.1g', vmin=-1, vmax=1, center= 0,  ax=ax)",
      "total-ns": 3489867
    },
    {
      "raw": "# # Check the sector values\n# fig, ax = plt.subplots(figsize=(10,10)) \n# chart = sns.barplot(x=df.sector.value_counts().index, y=df.sector.value_counts())\n# _= chart.set_xticklabels(chart.get_xticklabels(), rotation=75)",
      "total-ns": 195401
    },
    {
      "raw": "# Set a simpler name\ndf.rename(columns={'avg_salary_estimate':'avg_salary'}, inplace= True)",
      "total-ns": 897287
    },
    {
      "raw": "# Obtain the avg. salary for each type of role\npd.pivot_table(df,index='job_role', values='avg_salary')",
      "total-ns": 6200377
    },
    {
      "raw": "# Obtain the avg. salary based on the seniority of the roles\npd.pivot_table(df, index=['job_role','job_seniority'], values='avg_salary').sort_values('avg_salary', ascending =False)",
      "total-ns": 10714246
    },
    {
      "raw": "df.head()",
      "total-ns": 379799
    },
    {
      "raw": "\n# Define a custom aggregation function to get the percentage of descriptions that include certain skill.\ndef ones_percentage(x):\n    return round((sum(1 for value in x if value == 1)/len(x))*100,2)\n\n# Create the pivot table with the custom aggregation function\npivot_table = pd.pivot_table(df, index='job_role', values=['excel', 'sql', 'python', 'power_bi', 'tableau', 'scikit', 'spark'], aggfunc=ones_percentage)\n\nprint(pivot_table)",
      "total-ns": 25780380
    }
  ]
}